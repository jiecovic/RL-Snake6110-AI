# configs/example.yaml
# Example configuration for training a PPO agent on Snake
# Training-only (headless). Human pygame play is handled by snake-play / watch scripts.

run:
  name: snake_ppo
  seed: 42
  num_envs: 16
  total_timesteps: 100_000_000
  checkpoint_freq: 100_000
  resume_checkpoint: null

level:
  height: 13
  width: 22
  food_count: 1

env:
  id: pov_pixel                 # env class selector (ENV_REGISTRY key)

observation:
  params:
    view_radius: 10

model:
  features_extractor:
    cnn:
      type: tile4
      features_dim: 512
  net_arch: [256, 128]

ppo:
  n_steps: 2048
  batch_size: 128
  n_epochs: 2
  gamma: 0.999
  ent_coef: 0.03
  learning_rate: 3e-4
  verbose: 0

eval:
  intermediate:
    enabled: true
    episodes: 10
    best_metric: mean_reward   # or: mean_score
    deterministic: true
    seed_offset: 10000

  final:
    enabled: true
    episodes: 100
    best_metric: mean_reward   # or: mean_score
    deterministic: true
    seed_offset: 20000

